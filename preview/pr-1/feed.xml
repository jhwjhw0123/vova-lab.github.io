<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="/vova-lab.github.io/preview/pr-/feed.xml" rel="self" type="application/atom+xml" /><link href="/vova-lab.github.io/preview/pr-/" rel="alternate" type="text/html" /><updated>2025-02-08T01:34:26+00:00</updated><id>/vova-lab.github.io/preview/pr-/feed.xml</id><title type="html">random lab site</title><subtitle>An engaging 1-3 sentence description of your lab.</subtitle><entry><title type="html">Asynchronous Decentralized Federated Lifelong Learning (ADFLL)</title><link href="/vova-lab.github.io/preview/pr-/2024/12/30/ADFLL.html" rel="alternate" type="text/html" title="Asynchronous Decentralized Federated Lifelong Learning (ADFLL)" /><published>2024-12-30T00:00:00+00:00</published><updated>2025-02-08T01:29:24+00:00</updated><id>/vova-lab.github.io/preview/pr-/2024/12/30/ADFLL</id><content type="html" xml:base="/vova-lab.github.io/preview/pr-/2024/12/30/ADFLL.html"><![CDATA[<p>This project introduces the Asynchronous Decentralized Federated Lifelong Learning (ADFLL) framework, an innovative approach to federated learning that addresses the limitations of synchronous training schedules and the lack of lifelong learning in conventional machine learning frameworks for medical applications. ADFLL enables asynchronous and continual learning across agents, allowing them to leverage both their own experiences and knowledge shared by others. The framework was evaluated using deep reinforcement learning (DRL) for landmark localization tasks across diverse imaging modalities, orientations, and sequences. Experimental results demonstrated that ADFLL outperforms baseline models in collaborative learning, showing superior performance on both in-distribution and out-of-distribution test sets. This robust, efficient, and flexible framework is well-suited for deployment in real-world applications requiring privacy-preserving and lifelong collaborative learning. Paper published in <em>Medical Imaging with Deep Learning</em> (MIDL) 2024, <a href="https://openreview.net/forum?id=FbM7sDDAZ4">Towards a Collective Medical Imaging AI: Enabling Continual Learning from Peers</a>. Github repo: https://github.com/guangyaoz/ADFLL.</p>

<figure class="figure">
  <a class="figure-image" aria-label="Illustration of asynchronous decentralized federated lifelong learning ADFLL set up for cross-modality 3D localization of spleen. The blue, orange, and green boxes represent different agents in the setup. Each agent sequentially encounters two different imaging modalities for along with experiences shared by the other nodes, enabling them to learn to localize the spleen across all four modalities as opposed to just the two they encountered .">
    <img src="/vova-lab.github.io/preview/pr-/images/ADFLL_Concept_Figure.png" style="
        width: 1000px;
        max-height: unset;
      " alt="Illustration of asynchronous decentralized federated lifelong learning ADFLL set up for cross-modality 3D localization of spleen. The blue, orange, and green boxes represent different agents in the setup. Each agent sequentially encounters two different imaging modalities for along with experiences shared by the other nodes, enabling them to learn to localize the spleen across all four modalities as opposed to just the two they encountered ." loading="lazy" onerror="this.src = '/vova-lab.github.io/preview/pr-/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      Illustration of asynchronous decentralized federated lifelong learning (ADFLL)
  set up for cross-modality 3D localization of spleen. The blue, orange, and green
  boxes represent different agents in the setup. Each agent sequentially encounters
  two different imaging modalities for along with experiences shared by the other
  nodes, enabling them to learn to localize the spleen across all four modalities (as
  opposed to just the two they encountered).

    </figcaption>
  
</figure>

<p>To further enhance the efficiency of the ADFLL framework, we integrate a reward distribution-preserving coreset compression technique for selective experience replay buffers. This method compresses stored experiences, reducing computational overhead while maintaining the model’s ability to mitigate catastrophic forgetting. Evaluated on tasks such as ventricle localization in the BRATS dataset and landmark localization in whole-body MRI, the compressed lifelong learning models demonstrated competitive performance with minimal impact on accuracy. For instance, the 10x compressed models achieved mean pixel distances close to conventional lifelong learning models, highlighting the viability of coreset compression in resource-constrained settings. This addition reinforces ADFLL’s scalability and adaptability to real-world applications. Paper published in <em>Medical Imaging with Deep Learning</em> (MIDL) 2023, <a href="https://proceedings.mlr.press/v227/zheng24a.html">Selective experience replay compression using coresets for lifelong deep reinforcement learning in medical imaging</a>.</p>

<p>To further address the challenges of deploying the ADFLL framework on low-compute edge devices in rapidly evolving imaging environments, we developed three image coreset algorithms for compressing and denoising medical images in selective experience replay. These include neighborhood averaging, neighborhood sensitivity-based sampling, and maximum entropy coresets, which achieve 27x compression while maintaining strong performance in localizing anatomical landmarks on DIXON water and fat MRI images. Notably, the maximum entropy coreset outperformed conventional lifelong learning models with an average distance error of 11.97±12.02 compared to 19.24±50.77, showcasing its potential to enhance efficiency and adaptability in real-world medical imaging applications. Paper on arXiv: <a href="https://arxiv.org/abs/2306.05310">A framework for dynamically training and adapting deep reinforcement learning models to different, low-compute, and continuously changing radiology deployment environments</a>.</p>

<p>This project is funded by DARPA, part of the Shared Experience Lifelong Learning (<a href="https://intelligencecommunitynews.com/darpa-launches-shell-program/">ShELL</a>) program. Collectively, we have published a paper on <em>Nature Machine Intelligence</em>, <a href="https://rdcu.be/dB9zt">A collective AI via lifelong learning and sharing at the edge</a>.</p>]]></content><author><name>Guangyao Zheng</name></author><category term="Personalized Healthcare" /><category term="Distributed Learning" /><category term="Continual Learning" /><category term="Medical Imaging" /><category term="Low-compute Optimization" /><summary type="html"><![CDATA[This project introduces the Asynchronous Decentralized Federated Lifelong Learning (ADFLL) framework, an innovative approach to federated learning that addresses the limitations of synchronous training schedules and the lack of lifelong learning in conventional machine learning frameworks for medical applications. ADFLL enables asynchronous and continual learning across agents, allowing them to leverage both their own experiences and knowledge shared by others. The framework was evaluated using deep reinforcement learning (DRL) for landmark localization tasks across diverse imaging modalities, orientations, and sequences. Experimental results demonstrated that ADFLL outperforms baseline models in collaborative learning, showing superior performance on both in-distribution and out-of-distribution test sets. This robust, efficient, and flexible framework is well-suited for deployment in real-world applications requiring privacy-preserving and lifelong collaborative learning. Paper published in Medical Imaging with Deep Learning (MIDL) 2024, Towards a Collective Medical Imaging AI: Enabling Continual Learning from Peers. Github repo: https://github.com/guangyaoz/ADFLL.]]></summary></entry><entry><title type="html">Biomarker Stroke Prediction</title><link href="/vova-lab.github.io/preview/pr-/2024/12/30/Biomarker.html" rel="alternate" type="text/html" title="Biomarker Stroke Prediction" /><published>2024-12-30T00:00:00+00:00</published><updated>2025-02-08T01:29:24+00:00</updated><id>/vova-lab.github.io/preview/pr-/2024/12/30/Biomarker</id><content type="html" xml:base="/vova-lab.github.io/preview/pr-/2024/12/30/Biomarker.html"><![CDATA[<p>This project explores the link between mitochondrial oxidative phosphorylation (OxPhos) abnormalities and stroke risk in patients with advanced congestive heart failure (CHF) undergoing continuous-flow left ventricular assist device (CF-LVAD) implantation. Stroke remains a significant complication for this patient population, and prior ischemic events may predispose individuals to systemic mitochondrial dysfunction, exacerbating their risk of new strokes post-implantation.</p>

<p>In this study, OxPhos complex proteins (complex I [C.I] through complex V [C.V]) were measured in blood leukocytes of 50 CF-LVAD patients, evenly split between those with and without prior stroke histories. Key findings revealed:</p>

<p>Patients with a history of stroke exhibited significantly lower levels of C.I, C.II, C.IV, and C.V proteins in both pre-and post-CF-LVAD implantation compared to those without prior strokes.
Post-CF-LVAD, oxidative phosphorylation protein levels were markedly reduced in the prior-stroke group compared to baseline.
Using machine learning techniques, including Least Absolute Shrinkage and Selection Operator (LASSO) and Random Forest models, the study identified six prognostic factors that accurately predicted postoperative stroke risk, achieving an area under the receiver operating characteristic (ROC) curve (AUC) of 0.93. These findings highlight a novel association between mitochondrial dysfunction at the systemic level and stroke risk in this patient group.</p>

<p>The project underscores the potential of OxPhos protein expression as a biomarker for identifying patients at heightened risk of stroke following CF-LVAD implantation. Further research will refine these biomarkers and explore targeted interventions to mitigate postoperative stroke risk in CHF patients.</p>

<p>Paper published in <em>American Society for Artificial Internal Organs</em> (ASAIO): <a href="https://journals.lww.com/asaiojournal/abstract/9900/machine_learning_assisted_stroke_prediction_in.586.aspx">Machine Learning Assisted Stroke Prediction in Mechanical Circulatory Support: Predictive Role of Systemic Mitochondrial Dysfunction</a></p>]]></content><author><name>Guangyao Zheng</name></author><category term="Personalized Healthcare" /><category term="Biomarker" /><category term="Few-shot learning" /><summary type="html"><![CDATA[This project explores the link between mitochondrial oxidative phosphorylation (OxPhos) abnormalities and stroke risk in patients with advanced congestive heart failure (CHF) undergoing continuous-flow left ventricular assist device (CF-LVAD) implantation. Stroke remains a significant complication for this patient population, and prior ischemic events may predispose individuals to systemic mitochondrial dysfunction, exacerbating their risk of new strokes post-implantation.]]></summary></entry><entry><title type="html">Arrhythmia Detection and ECG Explainability</title><link href="/vova-lab.github.io/preview/pr-/2024/12/30/arrhythmia.html" rel="alternate" type="text/html" title="Arrhythmia Detection and ECG Explainability" /><published>2024-12-30T00:00:00+00:00</published><updated>2025-02-08T01:29:24+00:00</updated><id>/vova-lab.github.io/preview/pr-/2024/12/30/arrhythmia</id><content type="html" xml:base="/vova-lab.github.io/preview/pr-/2024/12/30/arrhythmia.html"><![CDATA[<p>This project addresses the critical challenges of arrhythmia detection and classification, particularly in the context of wearable electrocardiogram (ECG) monitoring devices. Unlike clinically controlled environments, wearable devices operate in noisy, real-world conditions, which complicates the accurate identification of arrhythmias. Additionally, the inherent imbalance in the ratio of normal heartbeats to arrhythmic ones, along with the diverse combinations of arrhythmia types, further compounds the difficulty of the task.</p>

<p>To tackle these challenges, we developed a novel hierarchical deep learning model that combines Convolutional Neural Networks (CNN), Bidirectional Long Short-Term Memory networks (BiLSTM), and an Attention mechanism. Our framework consists of two key modules:</p>

<ol>
  <li>A binary classification module to distinguish normal heartbeats from arrhythmic ones.</li>
  <li>A multi-label classification module to categorize arrhythmia events across combinations of beat and rhythm types.
The model was trained and evaluated on a proprietary dataset, achieving state-of-the-art performance metrics:</li>
</ol>

<figure class="figure">
  <a class="figure-image" aria-label="A to D is a flowchart of the proposed framework. C to D are proposed concepts of a hierarchical approach. A Multi-labeled wireless ECG arrhythmia raw data, B 4-beat input data after preprocessing, C Binary classification model for normal heartbeat and arrhythmia classification, D Multi-class, multi-label arrhythmia classification model, E Detailed structure of the proposed CNN BiLSTM with attention model.">
    <img src="/vova-lab.github.io/preview/pr-/images/arrhythmia.png" style="
        width: 1000px;
        max-height: unset;
      " alt="A to D is a flowchart of the proposed framework. C to D are proposed concepts of a hierarchical approach. A Multi-labeled wireless ECG arrhythmia raw data, B 4-beat input data after preprocessing, C Binary classification model for normal heartbeat and arrhythmia classification, D Multi-class, multi-label arrhythmia classification model, E Detailed structure of the proposed CNN BiLSTM with attention model." loading="lazy" onerror="this.src = '/vova-lab.github.io/preview/pr-/images/fallback.svg'; this.onerror = null;" />
  </a>
  
    <figcaption class="figure-caption">
      (A) to (D) is a flowchart of the proposed framework. (C) to (D) are proposed concepts of a hierarchical approach. (A) Multi-labeled wireless ECG arrhythmia raw data, (B) 4-beat input data after preprocessing, (C) Binary classification model for normal heartbeat and arrhythmia classification, (D) Multi-class, multi-label arrhythmia classification model, (E) Detailed structure of the proposed CNN + BiLSTM with attention model.

    </figcaption>
  
</figure>

<p>*Binary Classification: Accuracy: 95%, F1-score: 0.838, AUC: 0.906.
*Multi-label Classification: Accuracy: 88%, F1-score: 0.736, AUC: 0.875.
We benchmarked our framework against strong baselines, including CNN+BiGRU with Attention, ConViT, EfficientNet, and ResNet, as well as previous state-of-the-art methods, demonstrating its superior performance.</p>

<p>Our model offers a promising solution for real-world arrhythmia detection and classification, providing:</p>

<ul>
  <li>Enhanced diagnostic efficiency by reducing the workload on cardiologists.</li>
  <li>Personalized treatment options by enabling accurate, continuous monitoring.</li>
  <li>Emergency intervention capabilities through real-time arrhythmia monitoring on wearable devices.
This framework has the potential to revolutionize arrhythmia management, improving patient outcomes and advancing the integration of AI in healthcare. Paper published in <em>Digital Health</em>: <a href="https://journals.sagepub.com/doi/full/10.1177/20552076241278942">Hierarchical Deep Learning for Autonomous Multi-label Arrhythmia Detection and Classification on Real-world Wearable ECG Data</a></li>
</ul>

<p>Additionally, the lack of transparent justifications for decisions made by deep learning models poses challenges for real-world applications.</p>

<p>In this project, we utilized signals from a portable single-lead ECG device to classify eight arrhythmia classes using convolutional neural networks (CNN), achieving 79.91% accuracy on a single heartbeat. To enhance model interpretability, we incorporated Layer-Wise Relevance Propagation (LRP), an explainable artificial intelligence (XAI) algorithm, to analyze the distinctive features of each arrhythmia.</p>

<p>The XAI analysis revealed that for ventricular premature contraction (VPC), the model demonstrated strong activations in the QRS complex and T-wave regions. This aligns with medical interpretations that a wide QRS complex and an oppositely directed T-wave are characteristic of VPC. Such findings emphasize the potential for deep learning models to offer not only accurate predictions but also insights that align with clinical knowledge, supporting biomarker discovery for arrhythmia classification.</p>

<p>This research contributes to interpretable deep learning for arrhythmia diagnosis by:</p>

<ul>
  <li>Enhancing decision support systems with transparent and interpretable predictions.</li>
  <li>Facilitating biomarker discovery for arrhythmia management.</li>
  <li>Improving trust in AI systems through alignment with clinical knowledge.
These advancements pave the way for more explainable, reliable, and effective deep learning models in healthcare. Paper published in <em>International Conference on Artificial Intelligence in Medicine</em> (AIME) 2024: <a href="https://link.springer.com/chapter/10.1007/978-3-031-66535-6_31">Exploring the Possibility of Arrhythmia Interpretation of Time Domain ECG Using XAI: A Preliminary Study</a></li>
</ul>]]></content><author><name>Guangyao Zheng</name></author><category term="Personalized Healthcare" /><category term="Multi-label Classification" /><category term="Wearable Device" /><category term="Cardiovascular Health" /><category term="Explainability" /><category term="Interpretability" /><summary type="html"><![CDATA[This project addresses the critical challenges of arrhythmia detection and classification, particularly in the context of wearable electrocardiogram (ECG) monitoring devices. Unlike clinically controlled environments, wearable devices operate in noisy, real-world conditions, which complicates the accurate identification of arrhythmias. Additionally, the inherent imbalance in the ratio of normal heartbeats to arrhythmic ones, along with the diverse combinations of arrhythmia types, further compounds the difficulty of the task.]]></summary></entry></feed>